{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: Create a neural network class\n",
    "\n",
    "---\n",
    "\n",
    "Based on previous code examples, develop a neural network class that is able to classify any dataset provided. The class should create objects based on the desired network architecture:\n",
    "\n",
    "1. Number of inputs\n",
    "2. Number of hidden layers\n",
    "3. Number of neurons per layer\n",
    "4. Number of outputs\n",
    "5. Learning rate\n",
    "\n",
    "The class must have the train, and predict functions.\n",
    "\n",
    "Test the neural network class on the datasets provided below: Use the input data to train the network, and then pass new inputs to predict on. Print the expected label and the predicted label for the input you used. Print the accuracy of the training after predicting on different inputs.\n",
    "\n",
    "Use matplotlib to plot the error that the train method generates.\n",
    "\n",
    "**Don't forget to install Keras and tensorflow in your environment!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Needed for the mnist data\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical \n",
    "# ?np.random.randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, architecture, alpha):\n",
    "        '''\n",
    "            layers: List of integers which represents the architecture of the network.\n",
    "            alpha:  Learning rate.\n",
    "        '''\n",
    "        # TODO: Initialize the list of weights matrices, then store\n",
    "        # the network architecture and learning rate\n",
    "#         1. Number of inputs\n",
    "#         2. Number of hidden layers\n",
    "#         3. Number of neurons per layer\n",
    "#         4. Number of outputs\n",
    "#         5. Learning rate\n",
    "        self.n_inputs = architecture[0]\n",
    "        self.n_hidden_layers = architecture[1]\n",
    "        self.n_neurons = architecture[2]\n",
    "        self.n_outputs = architecture[3]\n",
    "        self.alpha = alpha\n",
    "        print(\"created network with: \",self.n_inputs,\" inputs,\",self.n_hidden_layers,\" hiddden layers, \",self.n_neurons,\" neurons and \",self.n_outputs,\" outputs\")\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        #initialize weights and biases\n",
    "        for i in range(self.n_hidden_layers+1):\n",
    "            if i == 0:\n",
    "                self.weights.append(np.random.randn(self.n_inputs, self.n_neurons))\n",
    "                self.biases.append(np.random.randn(self.n_neurons))\n",
    "            elif i < self.n_hidden_layers:\n",
    "                self.weights.append(np.random.randn(self.n_neurons,self.n_neurons))\n",
    "                self.biases.append(np.random.randn(self.n_neurons))\n",
    "            else:\n",
    "                self.weights.append(np.random.randn(self.n_neurons,self.n_outputs))\n",
    "                self.biases.append(np.random.randn(self.n_outputs))\n",
    "#             print(self.weights[i].shape)\n",
    "#             print(self.biases[i].shape)\n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "    def __repr__(self): \n",
    "        # construct and return a string that represents the network \n",
    "        # architecture \n",
    "        return \"NeuralNetwork: {}\".format( \"-\".join(str(l) for l in self.layers))\n",
    "\n",
    "    def softmax(X):  \n",
    "        # applies the softmax function to a set of values\n",
    "        \n",
    "        expX = np.exp(X)\n",
    "        return expX / expX.sum(axis=1, keepdims=True)\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        # the sigmoid for a given input value\n",
    "        \n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self, x):\n",
    "        # the derivative of the sigmoid\n",
    "        \n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        # TODO: Define the predict function\n",
    "       \n",
    "    #predictions\n",
    "        values = []\n",
    "        value = inputs\n",
    "        \n",
    "        \n",
    "#        print(\"shape w:\", w.shape,\" shape value:\",value.shape)\n",
    "        index=0\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            value = self.sigmoid(np.dot(value,w)+b)\n",
    "            if index==len(self.biases)-1 and self.n_outputs == 1:\n",
    "                continue\n",
    "            elif index==len(self.biases)-1 and self.n_outputs > 1:\n",
    "                value = self.softmax(np.dot(value,w)+b)\n",
    "            index+=1\n",
    "            \n",
    "            values.append(value)\n",
    "#             print(value)\n",
    "\n",
    "        return values\n",
    "\n",
    "        \n",
    "    def train(self, inputs, labels, epochs = 1000, displayUpdate = 100):\n",
    "        # TODO: Define the training step for the network. It should include the forward and back propagation\n",
    "        # steps, the updating of the weights, and it should print the error every 'displayUpdate' epochs\n",
    "        # It must return the errors so that they can be displayed with matplotlib\n",
    "        np.random.seed(69)\n",
    "        errors = []\n",
    "#         print(inputs.shape)\n",
    "        for e in range(epochs):\n",
    "            \n",
    "            #feed forward\n",
    "            predictions = self.predict(inputs)\n",
    "            #error from the last prediction\n",
    "            error = labels - predictions[-1]                 #element wise \n",
    "            errors.append(np.mean(np.abs(error)))\n",
    "            \n",
    "            deltas = []\n",
    "            bias_deltas = []\n",
    "            \n",
    "            \n",
    "            if e % displayUpdate == 0:\n",
    "                print(\"error in epoch \",e,\" is: \",np.mean(np.abs(errors)))\n",
    "                \n",
    "            deltas.append(error * self.sigmoid_deriv(predictions[-1]))\n",
    "            #backpropagation\n",
    "            for layer in range(1,self.n_hidden_layers+1):\n",
    "                level_error = np.dot(deltas[-layer],self.weights[-layer].T)\n",
    "                deltas.append(level_error * self.sigmoid_deriv(predictions[-(layer+1)]))\n",
    "                bias_deltas.append(np.sum(deltas[-layer]))\n",
    "                #update weights\n",
    "                self.weights[-layer]+=np.dot(predictions[-(layer+1)].T, deltas[-layer])*self.alpha\n",
    "                \n",
    "                self.bias[-layer]+=bias_deltas[-layer]*self.alpha                \n",
    "                \n",
    "            \n",
    "        return errors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dataset\n",
    "XOR_inputs = np.array([  \n",
    "                [0,0],\n",
    "                [0,1],\n",
    "                [1,0],\n",
    "                [1,1]\n",
    "            ])\n",
    "\n",
    "# labels dataset            \n",
    "XOR_labels = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created network with:  2  inputs, 2  hiddden layers,  2  neurons and  1  outputs\n",
      "error in epoch  0  is:  0.5040089155000581\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6050aae3102b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskynet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXOR_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXOR_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-ce5500019069>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, labels, epochs, displayUpdate)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m#backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden_layers\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mlevel_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mdeltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_deriv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mbias_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Test the class with the XOR data\n",
    "skynet = NeuralNetwork([2,2,2,1],0.1)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error')\n",
    "\n",
    "errors = skynet.train(XOR_inputs, XOR_labels)\n",
    "ax.plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the data points for each class\n",
    "class_1 = np.random.randn(700, 2) + np.array([0, -3])  \n",
    "class_2 = np.random.randn(700, 2) + np.array([3, 3])  \n",
    "class_3 = np.random.randn(700, 2) + np.array([-3, 3])\n",
    "\n",
    "feature_set = np.vstack([class_1, class_2, class_3])\n",
    "\n",
    "labels = np.array([0]*700 + [1]*700 + [2]*700)\n",
    "\n",
    "one_hot_labels = np.zeros((2100, 3))\n",
    "\n",
    "for i in range(2100):  \n",
    "    one_hot_labels[i, labels[i]] = 1\n",
    "\n",
    "plt.figure(figsize=(10,10))  \n",
    "plt.scatter(feature_set[:,0], feature_set[:,1], c=labels, s=30, alpha=0.5)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Test the class with the multiple classes data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the mnist data set\n",
    "\n",
    "---\n",
    "Train the network to classify hand drawn digits.\n",
    "\n",
    "For this data set, if the training step is taking too long, you can try to adjust the architecture of the network to have fewer layers, or you could try to train it with fewer input. The data has already been loaded and preprocesed so that it can be used with the network.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data from the mnist data set\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Plot a sample data point\n",
    "plt.title(\"Label: \" + str(train_labels[0]))\n",
    "plt.imshow(train_images[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "\n",
    "# Flatten the images\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "# turn values from 0-255 to 0-1\n",
    "train_images = train_images.astype('float32') / 255 \n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28)) \n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Create one hot encoding for the labels\n",
    "train_labels = to_categorical(train_labels) \n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the class with the mnist data. Test the training of the network with the test_images data, and \n",
    "# record the accuracy of the classification.\n",
    "\n",
    "skynet = NeuralNetwork([784,2,16,10],0.1)\n",
    "skynet.train(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After predicting on the *test_images*, use matplotlib to display some of the images that were not correctly classified. Then, answer the following questions: \n",
    "\n",
    "1. **Why do you think those were incorrectly classified?**\n",
    "2. **What could you try doing to improve the classification accuracy?**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
